{
    "collab_server" : "",
    "contents" : "install.packages(\"tm\") # Text Mining\ninstall.packages(\"SnowballC\")\ninstall.packages(\"caTools\")\ninstall.packages(\"caret\")\ninstall.packages(\"e1071\")\ninstall.packages(\"wordcloud\")\n\nlibrary(stringr)\nlibrary(tm) # text mining\nlibrary(SnowballC)  # Raiz palabras\n\n\nlibrary(caret)\nlibrary(e1071)\nlibrary(plyr)\n\nlibrary(caTools)\n\n\n\ngetwd()\n\ntweets = read.csv(\"extraccioniaLasso2b.csv\", sep = \",\" , encoding=\"UTF-8\", stringsAsFactors=FALSE)\ntable(tweets$sentimiento)\n\ncorpus = Corpus(VectorSource(tweets$tweet))\n\ncorpus = tm_map(corpus, tolower) # texto a minusculas\ncorpus = tm_map(corpus, PlainTextDocument) # \ncorpus <- tm_map(corpus, removePunctuation)\ncorpus = tm_map(corpus, removeWords, c(stopwords(\"es\"),\"elecciones2017ec\"))\ncorpus = tm_map(corpus, stripWhitespace)\ncorpus = tm_map(corpus, stemDocument, language=\"es\")\n\nfrequencies = DocumentTermMatrix(corpus)\n\n# Eliminar palabras poco repetidas\nsparse <- removeSparseTerms(frequencies, sparse = 0.995)\ntweetsSparse <- as.data.frame(as.matrix(sparse))\ncolnames(tweetsSparse) = make.names(colnames(tweetsSparse))\ntweetsSparse$sentimiento <- tweets$sentimiento\nset.seed(12)\n\nsplit <- sample.split(tweetsSparse$sentimiento, SplitRatio = 0.8)\n\ntrainSparse = subset(tweetsSparse, split=TRUE)\ntestSparse = subset(tweetsSparse, split=FALSE)\n\ntable(testSparse$sentimiento)\n\n# Evaluar el modelo\n\n\n# Entrenar modelo\nSVM <- svm(as.factor(sentimiento)~ ., data = trainSparse)\nsummary(SVM)\ntrainSparse\n\npredictSVM <- predict(SVM, newdata = testSparse)\n\ntable(predictSVM)\nconfusionMatrix(predictSVM, testSparse$sentimiento)\n\n\n# Test data.\ndata2 <- c('Voy a votar por lenin para ir por mas')\ncorpus <- VCorpus(VectorSource(data2))\ntdm <- DocumentTermMatrix(corpus, control = list(dictionary = tweetsSparse, removePunctuation = TRUE, stopwords = TRUE, stemming = TRUE, removeNumbers = TRUE))\ntest <- as.matrix(tdm)\n\n# Check accuracy on test.\npredict(SVM, newdata = test)\n\n\n\n\n\n\n\n\n\n\n\n# Nubes de palabras\nlibrary(wordcloud)\npositive <- subset(tweetsSparse, tweetsSparse$sentimiento==1)\npositive$sentimiento <- NULL\npositivas <- as.data.frame(colSums(positive))\npositivas$words <- row.names(positivas)\ncolnames(positivas) <- c(\"freq\",\"word\")\nwordcloud(positivas$word, positivas$freq, random.order = FALSE, colors = brewer.pal(8 , \"Dark2\"), max.words = 50, res=100)\n\n\n\n\n\n\n\n",
    "created" : 1499402508592.000,
    "dirty" : true,
    "encoding" : "",
    "folds" : "",
    "hash" : "2272251718",
    "id" : "FFF46897",
    "lastKnownWriteTime" : 1499397214,
    "last_content_update" : 1499404429163,
    "path" : null,
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}